#!/usr/bin/env python3
"""
AIç”µè¯å¤„ç†å™¨ - é›†æˆSTT, LLM, TTSå®Œæ•´å¯¹è¯æµ
"""

import io
import wave
import threading
import queue
import time
import numpy as np
from typing import Optional, Callable

class AIPhoneHandler:
    """AIç”µè¯å¤„ç†å™¨ - å¤„ç†å®Œæ•´çš„è¯­éŸ³å¯¹è¯æµç¨‹"""
    
    def __init__(self):
        self.stt_service = None
        self.llm_service = None
        self.tts_service = None
        
        # éŸ³é¢‘ç¼“å†²
        self.audio_buffer = queue.Queue()
        self.audio_samples = []
        self.sample_rate = 8000
        self.is_processing = False
        
        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        self.vad_threshold = 500  # ç®€å•çš„éŸ³é‡é˜ˆå€¼
        self.silence_duration = 1.5  # 1.5ç§’é™éŸ³åå¤„ç†
        self.last_audio_time = 0
        
        # å›è°ƒå‡½æ•°
        self.audio_callback = None
        
        # å¤„ç†çº¿ç¨‹
        self.processing_thread = None
        self.running = False
        
        # å¯¹è¯çŠ¶æ€æ˜¾ç¤º
        self.conversation_state = "ç­‰å¾…æ¥ç”µ"
        self.last_activity_time = time.time()
        self.status_display_count = 0
        
    def initialize_ai_services(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        try:
            # å°è¯•å¯¼å…¥æœ¬åœ°AIæœåŠ¡
            from local_ai import LocalLLM, LocalTTS, LocalSTT
            
            print("ğŸ§  åˆå§‹åŒ–LLMæœåŠ¡...")
            self.llm_service = LocalLLM(
                model_name="Qwen/Qwen2.5-7B-Instruct",
                device="cuda",
                use_4bit=True
            )
            print("âœ… LLMå°±ç»ª")
            
            print("ğŸ—£ï¸ åˆå§‹åŒ–TTSæœåŠ¡...")
            self.tts_service = LocalTTS()
            print("âœ… TTSå°±ç»ª")
            
            print("ğŸ¤ åˆå§‹åŒ–STTæœåŠ¡...")
            self.stt_service = LocalSTT(
                model="small",  # ä½¿ç”¨smallæ¨¡å‹å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦
                language="zh",
                device="cuda"
            )
            # è®¾ç½® STT è½¬å½•å›è°ƒ
            self.stt_service.set_transcription_callback(self._on_speech_recognized)
            self.stt_service.start_listening()
            print("âœ… STTå°±ç»ª")
            
            return True
            
        except Exception as e:
            print(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def set_audio_callback(self, callback: Callable):
        """è®¾ç½®éŸ³é¢‘è¾“å‡ºå›è°ƒ"""
        self.audio_callback = callback
    
    def start(self):
        """å¯åŠ¨AIå¤„ç†å™¨"""
        if not self.initialize_ai_services():
            return False
            
        self.running = True
        # ä¸å†éœ€è¦å¤„ç†çº¿ç¨‹ï¼Œä½¿ç”¨å®æ—¶STTå›è°ƒ
        
        print("ğŸ¤– AIç”µè¯å¤„ç†å™¨å·²å¯åŠ¨")
        return True
    
    def stop(self):
        """åœæ­¢AIå¤„ç†å™¨"""
        self.running = False
        if self.stt_service:
            self.stt_service.stop_listening()
        print("ğŸ¤– AIç”µè¯å¤„ç†å™¨å·²åœæ­¢")
    
    def process_audio_chunk(self, audio_data: bytes, payload_type: int):
        """å¤„ç†æ¥æ”¶åˆ°çš„éŸ³é¢‘å—"""
        try:
            # å°†Î¼-lawéŸ³é¢‘è½¬æ¢ä¸ºPCM
            from working_sip_client import G711Codec
            pcm_data = G711Codec.mulaw_to_pcm(audio_data)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºå¤„ç†
            samples = np.frombuffer(pcm_data, dtype=np.int16)
            
            # ç®€å•çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹
            audio_level = np.sqrt(np.mean(samples.astype(np.float32) ** 2))
            
            # ç›´æ¥å°†éŸ³é¢‘æ•°æ®å‘é€ç»™STTæœåŠ¡
            if self.stt_service:
                self.stt_service.feed_audio(audio_data)
            
            # æ˜¾ç¤ºè¯­éŸ³æ´»åŠ¨çŠ¶æ€ï¼ˆå‡å°‘æ—¥å¿—ï¼‰
            if audio_level > self.vad_threshold:
                if not self.is_processing and len(self.audio_samples) == 0:
                    self._update_conversation_state("ğŸ¤ æ­£åœ¨å¬å–è¯­éŸ³...")
                # ç§¯ç´¯éŸ³é¢‘æ•°æ®ç”¨äºå¤‡ç”¨å¤„ç†
                self.audio_samples.extend(samples)
                self.last_audio_time = time.time()
                    
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
    
    def _process_accumulated_audio(self):
        """å¤„ç†ç§¯ç´¯çš„éŸ³é¢‘æ•°æ®"""
        if not self.audio_samples or self.is_processing:
            return
            
        self.is_processing = True
        
        try:
            # å°†éŸ³é¢‘æ ·æœ¬åŠ å…¥å¤„ç†é˜Ÿåˆ—
            audio_array = np.array(self.audio_samples, dtype=np.int16)
            self.audio_buffer.put(audio_array)
            
            print(f"ğŸ¤ è¯­éŸ³ç»“æŸï¼Œå¤„ç† {len(self.audio_samples)} ä¸ªæ ·æœ¬ ({len(self.audio_samples)/self.sample_rate:.1f}ç§’)")
            
            # æ¸…ç©ºç¼“å†²åŒº
            self.audio_samples = []
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç§¯ç´¯å¤„ç†é”™è¯¯: {e}")
        finally:
            self.is_processing = False
    
    # ä¸å†éœ€è¦å¾ªç¯å¤„ç†ï¼Œå› ä¸ºä½¿ç”¨å®æ—¶STTå›è°ƒ
    # def _processing_loop å·²ç§»é™¤
    
    # ä¸å†éœ€è¦ï¼Œå› ä¸ºä½¿ç”¨å®æ—¶STTå›è°ƒ
    # def _process_conversation å·²ç§»é™¤
    
    def _on_speech_recognized(self, text: str):
        """è¯­éŸ³è¯†åˆ«å›è°ƒå‡½æ•°"""
        try:
            if text and text.strip():
                self._update_conversation_state(f"ğŸ¤ ç”¨æˆ·: {text}")
                
                # ç”Ÿæˆå›å¤
                self._update_conversation_state("ğŸ§  AIæ€è€ƒä¸­...")
                response = self._generate_response(text)
                if response:
                    self._update_conversation_state(f"ğŸ¤– AI: {response}")
                    
                    # æ–‡å­—è½¬è¯­éŸ³
                    self._update_conversation_state("ğŸ—£ï¸ æ­£åœ¨åˆæˆè¯­éŸ³...")
                    audio_response = self._text_to_speech(response)
                    if audio_response:
                        # å‘é€éŸ³é¢‘å›å¤
                        self._send_audio_response(audio_response)
                        self._update_conversation_state("ğŸ“ ç­‰å¾…ç”¨æˆ·è¯´è¯...")
                        
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«å›è°ƒé”™è¯¯: {e}")
    
    def _generate_response(self, user_text: str) -> Optional[str]:
        """ç”ŸæˆLLMå›å¤"""
        try:
            if not self.llm_service:
                # ä½¿ç”¨é»˜è®¤å›å¤
                return f"æ„Ÿè°¢æ‚¨è¯´'{user_text}'ã€‚æˆ‘æ˜¯OneSuite Businessçš„AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼"
            
            # æ„å»ºå¯¹è¯prompt
            prompt = f"""ä½ æ˜¯OneSuite Businessçš„ä¸“ä¸šAIå®¢æœåŠ©æ‰‹ã€‚ä½ éœ€è¦ç”¨ä¸­æ–‡å›å¤ã€‚

ç”¨æˆ·è¯´: "{user_text}"

è¯·æä¾›ä¸€ä¸ªç®€çŸ­ã€ä¸“ä¸šã€å‹å¥½çš„ä¸­æ–‡å›å¤ï¼ˆä¸è¶…è¿‡25å­—ï¼‰ã€‚åªè¿”å›å›å¤å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
            
            response = self.llm_service.generate_response(prompt)
            
            # é™åˆ¶å›å¤é•¿åº¦å¹¶æ¸…ç†æ ¼å¼
            response = response.strip()
            if len(response) > 40:
                response = response[:37] + "..."
                
            return response
            
        except Exception as e:
            print(f"âŒ LLMç”Ÿæˆé”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç†è§£æ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    def _text_to_speech(self, text: str) -> Optional[bytes]:
        """æ–‡å­—è½¬è¯­éŸ³"""
        try:
            if not self.tts_service:
                print("âš ï¸ TTSæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")
                return None
                
            print(f"ğŸ—£ï¸ å¼€å§‹TTSåˆæˆ: '{text}'")
            
            # ç”Ÿæˆè¯­éŸ³
            audio_data = self.tts_service.synthesize_text(text)
            
            if audio_data and len(audio_data) > 0:
                print(f"âœ… TTSæˆåŠŸç”Ÿæˆ {len(audio_data)} bytes Î¼-lawéŸ³é¢‘")
                return audio_data
            else:
                print("âŒ TTSæœªç”Ÿæˆæœ‰æ•ˆéŸ³é¢‘æ•°æ®")
                return None
                
        except Exception as e:
            print(f"âŒ TTSå¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _send_audio_response(self, audio_data: bytes):
        """å‘é€éŸ³é¢‘å›å¤"""
        try:
            if not self.audio_callback:
                print("âš ï¸ æ²¡æœ‰éŸ³é¢‘å›è°ƒå‡½æ•°")
                return
                
            print(f"ğŸ“« å¼€å§‹å‘é€éŸ³é¢‘: {len(audio_data)} bytes")
            
            # TTSå·²ç»è¿”å›äº†Î¼-lawæ ¼å¼çš„æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
            mulaw_data = audio_data
            
            # åˆ†åŒ…å‘é€ (æ¯åŒ…160å­—èŠ‚ï¼Œ20ms)
            chunk_size = 160
            packets_sent = 0
            
            for i in range(0, len(mulaw_data), chunk_size):
                chunk = mulaw_data[i:i+chunk_size]
                if len(chunk) == chunk_size:  # åªå‘é€å®Œæ•´çš„åŒ…
                    self.audio_callback(chunk, payload_type=0)  # Î¼-law
                    packets_sent += 1
                    time.sleep(0.02)  # 20msé—´éš”
                elif len(chunk) > 0:  # å¯¹äºæœ€åä¸€ä¸ªä¸å®Œæ•´çš„åŒ…ï¼Œå¡«å……è‡³160å­—èŠ‚
                    padded_chunk = chunk + b'\x7f' * (chunk_size - len(chunk))  # ç”¨é™éŸ³å€¼å¡«å……
                    self.audio_callback(padded_chunk, payload_type=0)
                    packets_sent += 1
                    time.sleep(0.02)
            
            print(f"âœ… éŸ³é¢‘å‘é€å®Œæˆ: {packets_sent} ä¸ª RTP åŒ…")
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å‘é€é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    def send_welcome_message(self):
        """å‘é€æ¬¢è¿æ¶ˆæ¯"""
        welcome_text = "æ‚¨å¥½ï¼æ¬¢è¿è‡´ç”µOneSuite Businessï¼Œæˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ"
        
        self._update_conversation_state("ğŸ‰ å‘é€æ¬¢è¿æ¶ˆæ¯...")
        
        # ç›´æ¥ç”Ÿæˆå¹¶å‘é€æ¬¢è¿è¯­éŸ³
        audio_data = self._text_to_speech(welcome_text)
        if audio_data:
            self._send_audio_response(audio_data)
            self._update_conversation_state("ğŸ“ ç­‰å¾…ç”¨æˆ·è¯´è¯...")
        else:
            print("ğŸ¤– " + welcome_text)
            self._update_conversation_state("âŒ æ¬¢è¿æ¶ˆæ¯å‘é€å¤±è´¥")
    
    def _update_conversation_state(self, new_state: str):
        """æ›´æ–°å¯¹è¯çŠ¶æ€æ˜¾ç¤º"""
        self.conversation_state = new_state
        self.last_activity_time = time.time()
        
        # åœ¨åŒä¸€è¡Œæ›´æ–°çŠ¶æ€ï¼Œé¿å…åˆ·å±
        print(f"\rğŸ’¬ å¯¹è¯çŠ¶æ€: {new_state}", end="", flush=True)
        
        # å¦‚æœçŠ¶æ€æ˜¯æœ€ç»ˆçŠ¶æ€ï¼ˆç”¨æˆ·è¯´è¯æˆ–ç­‰å¾…ï¼‰ï¼Œåˆ™æ¢è¡Œ
        if "ç”¨æˆ·:" in new_state or "ç­‰å¾…" in new_state:
            print()  # æ¢è¡Œ