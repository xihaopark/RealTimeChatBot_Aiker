#!/usr/bin/env python3
"""
æœ¬åœ°AIæµç¨‹æµ‹è¯•
ä¸“æ³¨æµ‹è¯•STT -> LLM -> TTSçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import time
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from local_ai import LocalSTT, LocalTTS, LocalLLM, AudioConverter
import numpy as np

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_local_ai_pipeline():
    """æµ‹è¯•æœ¬åœ°AIå®Œæ•´æµç¨‹"""
    print("=== æœ¬åœ°AIæµç¨‹æµ‹è¯• ===")
    
    try:
        # 1. åˆå§‹åŒ–LLMï¼ˆæœ€é‡è¦çš„ç»„ä»¶ï¼‰
        print("ğŸ§  åˆå§‹åŒ–æœ¬åœ°LLM...")
        llm = LocalLLM(
            model_name="Qwen/Qwen2.5-7B-Instruct",
            device="cuda",
            use_4bit=True,
            max_length=1024,
            temperature=0.7
        )
        print("âœ… LLMåˆå§‹åŒ–å®Œæˆ")
        
        # 2. åˆå§‹åŒ–TTS
        print("ğŸ—£ï¸ åˆå§‹åŒ–æœ¬åœ°TTS...")
        tts = LocalTTS(
            engine="system",
            voice="zh",
            device="cuda"
        )
        print("âœ… TTSåˆå§‹åŒ–å®Œæˆ")
        
        # 3. åˆå§‹åŒ–STT
        print("ğŸ‘‚ åˆå§‹åŒ–æœ¬åœ°STT...")
        stt = LocalSTT(
            model="base",
            language="zh",
            device="cuda",
            mic=False
        )
        print("âœ… STTåˆå§‹åŒ–å®Œæˆ")
        
        # 4. æµ‹è¯•å®Œæ•´å¯¹è¯æµç¨‹
        test_conversations = [
            "ä½ å¥½",
            "OneSuiteå…¬å¸æä¾›ä»€ä¹ˆæœåŠ¡ï¼Ÿ",
            "ç”µè¯ç³»ç»Ÿçš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ"
        ]
        
        print("\nğŸ”„ å¼€å§‹æµ‹è¯•å¯¹è¯æµç¨‹...")
        
        for i, user_input in enumerate(test_conversations, 1):
            print(f"\n--- å¯¹è¯ {i} ---")
            print(f"ç”¨æˆ·: {user_input}")
            
            # STT: æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ï¼ˆè¿™é‡Œç›´æ¥ä½¿ç”¨æ–‡æœ¬ï¼‰
            stt_start = time.time()
            recognized_text = user_input  # å®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯STTçš„ç»“æœ
            stt_time = time.time() - stt_start
            print(f"STTç»“æœ ({stt_time:.2f}s): {recognized_text}")
            
            # LLM: ç”Ÿæˆå›å¤
            llm_start = time.time()
            ai_response = llm.generate_response(recognized_text)
            llm_time = time.time() - llm_start
            print(f"LLMå›å¤ ({llm_time:.2f}s): {ai_response}")
            
            # TTS: è¯­éŸ³åˆæˆ
            tts_start = time.time()
            audio_data = tts.synthesize_text(ai_response)
            tts_time = time.time() - tts_start
            print(f"TTSåˆæˆ ({tts_time:.2f}s): {len(audio_data)} bytes")
            
            # æ€»å“åº”æ—¶é—´
            total_time = stt_time + llm_time + tts_time
            print(f"æ€»å“åº”æ—¶é—´: {total_time:.2f}s")
            
            if total_time > 10:
                print("âš ï¸ å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–")
            elif total_time > 5:
                print("ğŸŸ¡ å“åº”æ—¶é—´ä¸­ç­‰")
            else:
                print("ğŸŸ¢ å“åº”æ—¶é—´è‰¯å¥½")
        
        # 5. æµ‹è¯•éŸ³é¢‘æ ¼å¼è½¬æ¢
        print("\nğŸ”„ æµ‹è¯•éŸ³é¢‘æ ¼å¼è½¬æ¢...")
        
        # ç”Ÿæˆæµ‹è¯•PCMéŸ³é¢‘
        test_pcm = np.random.randint(-16384, 16384, 1600, dtype=np.int16)  # 0.1s @ 16kHz
        
        # è½¬æ¢ä¸ºRTPæ ¼å¼
        rtp_audio = AudioConverter.convert_pcm16k_to_rtp(test_pcm)
        print(f"PCM->RTP: {len(test_pcm)} samples -> {len(rtp_audio)} bytes")
        
        # è½¬æ¢å›PCM
        recovered_pcm = AudioConverter.convert_rtp_to_pcm16k(rtp_audio)
        print(f"RTP->PCM: {len(rtp_audio)} bytes -> {len(recovered_pcm)} samples")
        
        print("âœ… éŸ³é¢‘è½¬æ¢æµ‹è¯•é€šè¿‡")
        
        # 6. æ€§èƒ½è¯„ä¼°
        print("\nğŸ“Š æ€§èƒ½è¯„ä¼°:")
        model_info = llm.get_model_info()
        print(f"- æ¨¡å‹: {model_info['model_name']}")
        print(f"- è®¾å¤‡: {model_info['device']}")
        print(f"- 4ä½é‡åŒ–: {model_info['use_4bit']}")
        print(f"- å¯¹è¯è½®æ•°: {model_info['conversation_turns']}")
        
        # æ¸…ç†èµ„æº
        tts.cleanup()
        
        return True
        
    except Exception as e:
        print(f"âŒ æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("VTX AI Phone System - æœ¬åœ°AIæµç¨‹æµ‹è¯•\n")
    
    success = test_local_ai_pipeline()
    
    if success:
        print("\nğŸ‰ æœ¬åœ°AIæµç¨‹æµ‹è¯•æˆåŠŸ!")
        print("ğŸ’¡ æç¤º: ç³»ç»Ÿå·²å‡†å¤‡å¥½å¤„ç†å®é™…è¯­éŸ³é€šè¯")
        return 0
    else:
        print("\nâŒ æœ¬åœ°AIæµç¨‹æµ‹è¯•å¤±è´¥")
        print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥GPUç¯å¢ƒå’Œæ¨¡å‹ä¸‹è½½")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)