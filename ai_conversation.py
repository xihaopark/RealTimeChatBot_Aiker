#!/usr/bin/env python3
"""
AIå¯¹è¯æ¨¡å— - é›†æˆSTTã€LLMã€TTSå®ç°æ™ºèƒ½è¯­éŸ³å¯¹è¯
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæé«˜è¯†åˆ«ç²¾åº¦ã€ä½¿ç”¨æ›´å¥½TTSã€ç­‰å¾…ç”¨æˆ·è¯´å®Œè¯
"""

import asyncio
import json
import time
import threading
import queue
import websockets
import aiohttp
import numpy as np
from typing import Optional, Callable
import os
import requests
import torch # For checking CUDA availability

# Import the new adapter
from src.adapters.stt_adapter import STTAdapter

class AIConversationManager:
    """AIå¯¹è¯ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        # åŠ è½½APIå¯†é’¥
        self.openai_api_key = self._load_api_key("api_keys/openai.key")
        self.deepgram_api_key = self._load_api_key("api_keys/deepgram.key")
        self.elevenlabs_api_key = self._load_api_key("api_keys/elevenlabs.key")
        
        # åŠ è½½OneSuite Businessä¸šåŠ¡æ•°æ®
        self.onesuite_data = self._load_onesuite_data("onesuite-business-data.json")
        print(f"âœ… OneSuite Business æ•°æ®åŠ è½½å®Œæˆ")
        
        # å¯¹è¯çŠ¶æ€
        self.is_conversing = False
        self.conversation_history = []
        self.audio_queue = queue.Queue()
        self.audio_buffer = b""
        self.last_speech_time = 0
        self.silence_threshold = 1.5  # 1.5ç§’é™éŸ³æ£€æµ‹
        
        # éŸ³é¢‘å›è°ƒå‡½æ•°
        self.audio_callback = None
        
        # æ™ºèƒ½éŸ³é¢‘å¤„ç†å‚æ•°
        self.min_audio_length = 2.0  # æœ€å°éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
        self.max_audio_length = 10.0  # æœ€å¤§éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
        self.is_processing_audio = False  # é˜²æ­¢é‡å¤å¤„ç†
        
        # Backend configuration from environment variables
        use_local_stt = os.getenv("USE_LOCAL_STT", "false").lower() == "true"
        
        # Initialize STT Adapter
        self.stt_adapter = STTAdapter(
            use_local=use_local_stt,
            config={
                "deepgram_api_key": self.deepgram_api_key,
                "model_path": "large-v3",
                "device": "cuda" if torch.cuda.is_available() else "cpu"
            }
        )
        print(f"STTé€‚é…å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å¼: {'æœ¬åœ°' if use_local_stt else 'API'}")

        # TTSè¯­éŸ³é…ç½® - Anna Suä½œä¸ºä¸»è¦è¯­éŸ³ï¼Œè‹±æ–‡è¯­éŸ³ä½œä¸ºå¤‡ç”¨
        self.primary_voice_id = "9lHjugDhwqoxA5MhX0az"  # Anna Su - Casual & Friendly (ä¸­æ–‡)
        self.fallback_voice_id = "EXAVITQu4vr4xnSDxMaL"  # Sarah - è‹±æ–‡å¥³å£° (å¤‡ç”¨)
        
        print("ğŸ¤– Aiker AIå¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"âœ… OpenAI API: {'å·²é…ç½®' if self.openai_api_key else 'æœªé…ç½®'}")
        print(f"âœ… Deepgram API: {'å·²é…ç½®' if self.deepgram_api_key else 'æœªé…ç½®'}")
        print(f"âœ… ElevenLabs API: {'å·²é…ç½®' if self.elevenlabs_api_key else 'æœªé…ç½®'}")
        print(f"ğŸ­ ä¸»è¦è¯­éŸ³: Anna Su (ä¸­æ–‡)")
        print(f"ğŸ­ å¤‡ç”¨è¯­éŸ³: Sarah (è‹±æ–‡)")
    
    def _load_api_key(self, filename: str) -> str:
        """åŠ è½½APIå¯†é’¥"""
        try:
            with open(filename, "r") as f:
                return f.read().strip()
        except Exception as e:
            print(f"âŒ åŠ è½½APIå¯†é’¥å¤±è´¥ {filename}: {e}")
            return ""
    
    def _load_onesuite_data(self, filename: str) -> dict:
        """åŠ è½½ä¸šåŠ¡æ•°æ®JSONæ–‡ä»¶"""
        try:
            with open(filename, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½ä¸šåŠ¡æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def set_audio_callback(self, callback: Callable):
        """è®¾ç½®éŸ³é¢‘å›è°ƒå‡½æ•°"""
        self.audio_callback = callback
    
    def start_conversation(self):
        """å¼€å§‹AIå¯¹è¯"""
        self.is_conversing = True
        self.conversation_history = []
        self.audio_buffer = b""
        self.last_speech_time = time.time()
        
        # å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹
        self.audio_thread = self.start_audio_processing_thread()
        
        print("ğŸ¤ å¼€å§‹Aiker AIå¯¹è¯...")
        
        # å‘é€æ¬¢è¿æ¶ˆæ¯ - ä¼˜å…ˆä½¿ç”¨é¢„ç”Ÿæˆçš„éŸ³é¢‘
        welcome_message = "æ‚¨å¥½ï¼æˆ‘æ˜¯Aikerï¼ŒOneSuite Businessçš„ä¸“ä¸šå®¢æœåŠ©æ‰‹ã€‚æˆ‘ä»¬æä¾›æœ€å®æƒ çš„è™šæ‹Ÿç”µè¯ç³»ç»Ÿï¼ŒåŒ…æ‹¬è™šæ‹ŸPBXã€çŸ­ä¿¡æœåŠ¡ã€è‡ªåŠ¨æ¥å¾…å‘˜ç­‰åŠŸèƒ½ã€‚è¯·é—®æ‚¨æƒ³äº†è§£æˆ‘ä»¬å…¬å¸çš„å“ªäº›æœåŠ¡ï¼Ÿ"
        self._process_welcome_message(welcome_message)
    
    def stop_conversation(self):
        """åœæ­¢å¯¹è¯"""
        self.is_conversing = False
        print("ğŸ”‡ AIå¯¹è¯å·²åœæ­¢")
    
    def process_audio_input(self, audio_data: bytes):
        """å¤„ç†è¾“å…¥çš„éŸ³é¢‘æ•°æ® - æ™ºèƒ½å¥å­å®Œæ•´æ€§æ£€æµ‹"""
        if not self.is_conversing or self.is_processing_audio:
            return
        
        # æ·»åŠ åˆ°éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer += audio_data
        self.last_speech_time = time.time()
        
        # è®¡ç®—å½“å‰éŸ³é¢‘é•¿åº¦
        audio_duration = len(self.audio_buffer) / 8000  # 8kHzé‡‡æ ·ç‡
        
        # æ™ºèƒ½å¤„ç†ç­–ç•¥ï¼š
        # 1. å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œç»§ç»­æ”¶é›†
        # 2. å¦‚æœéŸ³é¢‘è¶³å¤Ÿé•¿ä¸”é™éŸ³ï¼Œå¤„ç†
        # 3. å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œå¼ºåˆ¶å¤„ç†
        if audio_duration >= self.min_audio_length:
            # æ£€æŸ¥æ˜¯å¦é™éŸ³è¶³å¤Ÿé•¿ï¼ˆå¥å­ç»“æŸï¼‰
            if time.time() - self.last_speech_time > self.silence_threshold:
                self._process_complete_audio()
            # å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œå¼ºåˆ¶å¤„ç†
            elif audio_duration >= self.max_audio_length:
                self._process_complete_audio()

    def _process_complete_audio(self):
        """å¤„ç†å®Œæ•´çš„éŸ³é¢‘ç‰‡æ®µ"""
        if self.is_processing_audio or len(self.audio_buffer) == 0:
            return
        
        self.is_processing_audio = True
        
        try:
            # è¯­éŸ³è¯†åˆ«
            text = self._speech_to_text(self.audio_buffer)
            if text and len(text.strip()) > 0:
                print(f"ğŸ‘¤ ç”¨æˆ·è¯´: {text}")
                
                # è·å–AIå›å¤
                ai_response = self._get_ai_response(text)
                if ai_response:
                    self._process_ai_response(ai_response)
            
            # æ¸…ç©ºç¼“å†²åŒº
            self.audio_buffer = b""
                    
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
        finally:
            self.is_processing_audio = False

    def _process_audio_buffer_immediate(self, audio_data: bytes):
        """ç«‹å³å¤„ç†éŸ³é¢‘ç¼“å†²åŒº - ä¸ç­‰å¾…é™éŸ³ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        try:
            # è¯­éŸ³è¯†åˆ«
            text = self._speech_to_text(audio_data)
            if text and len(text.strip()) > 0:
                print(f"ğŸ‘¤ ç”¨æˆ·è¯´: {text}")
                
                # è·å–AIå›å¤
                ai_response = self._get_ai_response(text)
                if ai_response:
                    self._process_ai_response(ai_response)
                    
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")

    def _process_audio_buffer(self):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº - é™éŸ³æ£€æµ‹ç‰ˆæœ¬ï¼ˆå¤‡ç”¨ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦é™éŸ³æ—¶é—´è¶³å¤Ÿé•¿
            if time.time() - self.last_speech_time > self.silence_threshold:
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get()
                    self._process_audio_buffer_immediate(audio_data)
                            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")

    def _process_welcome_message(self, text: str):
        """å¤„ç†æ¬¢è¿æ¶ˆæ¯ - ä¼˜å…ˆä½¿ç”¨é¢„ç”Ÿæˆçš„éŸ³é¢‘"""
        try:
            print(f"ğŸ¤– Aikerå›å¤: {text}")
            
            # å°è¯•åŠ è½½é¢„ç”Ÿæˆçš„æ¬¢è¿è¯­éŸ³
            audio_data = self._load_pregenerated_welcome_audio()
            
            if audio_data:
                print("ğŸµ ä½¿ç”¨é¢„ç”Ÿæˆçš„æ¬¢è¿è¯­éŸ³")
                # ç›´æ¥é€šè¿‡audio_callbackå‘é€é¢„ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®
                if self.audio_callback:
                    self.audio_callback(audio_data)
            else:
                print("âš ï¸ é¢„ç”ŸæˆéŸ³é¢‘ä¸å­˜åœ¨ï¼Œä½¿ç”¨å®æ—¶TTS")
                # å›é€€åˆ°å®æ—¶TTS
                self._process_ai_response(text)
                
        except Exception as e:
            print(f"âŒ æ¬¢è¿æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
            # å›é€€åˆ°å®æ—¶TTS
            self._process_ai_response(text)
    
    def _load_pregenerated_welcome_audio(self) -> bytes | None:
        """åŠ è½½é¢„ç”Ÿæˆçš„æ¬¢è¿è¯­éŸ³"""
        try:
            import os
            
            # æ£€æŸ¥é¢„ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            audio_files = [
                "audio/welcome_chinese.ulaw",
                "welcome_chinese.ulaw",
                "audio/welcome.ulaw",
                "welcome.ulaw"
            ]
            
            for audio_file in audio_files:
                if os.path.exists(audio_file):
                    print(f"ğŸ“ æ‰¾åˆ°é¢„ç”ŸæˆéŸ³é¢‘: {audio_file}")
                    with open(audio_file, 'rb') as f:
                        audio_data = f.read()
                    
                    # éªŒè¯éŸ³é¢‘æ–‡ä»¶
                    if len(audio_data) > 0:
                        print(f"ğŸ“Š éŸ³é¢‘æ–‡ä»¶å¤§å°: {len(audio_data)} å­—èŠ‚, æ—¶é•¿: {len(audio_data)/8000:.2f} ç§’")
                        return audio_data
                    
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¢„ç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
            return None
            
        except Exception as e:
            print(f"âŒ åŠ è½½é¢„ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
            return None

    def _send_pregenerated_audio(self, audio_data: bytes):
        """å‘é€é¢„ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®ï¼ˆå·²ç»æ˜¯Î¼-lawæ ¼å¼ï¼‰"""
        try:
            if not self.audio_callback:
                print("âŒ éŸ³é¢‘å›è°ƒæœªè®¾ç½®")
                return
            
            # é¢„ç”Ÿæˆçš„éŸ³é¢‘å·²ç»æ˜¯Î¼-lawæ ¼å¼ï¼ŒæŒ‰160å­—èŠ‚åˆ†åŒ…å‘é€
            packet_size = 160  # 20ms @ 8kHz
            print(f"ğŸ“¤ å¼€å§‹å‘é€é¢„ç”ŸæˆéŸ³é¢‘: {len(audio_data)} å­—èŠ‚")
            
            # åˆ›å»ºä¸€ä¸ªçº¿ç¨‹æ¥å‘é€éŸ³é¢‘ï¼Œé¿å…é˜»å¡
            def send_audio_thread():
                try:
                    for i in range(0, len(audio_data), packet_size):
                        packet = audio_data[i:i+packet_size]
                        
                        # ç¡®ä¿åŒ…å¤§å°æ­£ç¡®
                        if len(packet) < packet_size:
                            # ç”¨Î¼-lawé™éŸ³å¡«å……
                            packet += b'\xFF' * (packet_size - len(packet))
                        
                        # å‘é€éŸ³é¢‘åŒ…
                        if self.audio_callback:
                            self.audio_callback(packet)
                        
                        # 20msé—´éš”
                        import time
                        time.sleep(0.02)
                    
                    print("âœ… é¢„ç”ŸæˆéŸ³é¢‘å‘é€å®Œæˆ")
                    
                except Exception as e:
                    print(f"âŒ å‘é€é¢„ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
            
            # å¯åŠ¨å‘é€çº¿ç¨‹
            import threading
            audio_thread = threading.Thread(target=send_audio_thread)
            audio_thread.daemon = True
            audio_thread.start()
            
        except Exception as e:
            print(f"âŒ é¢„ç”ŸæˆéŸ³é¢‘å‘é€é”™è¯¯: {e}")

    def _process_ai_response(self, text: str):
        """å¤„ç†AIå›å¤"""
        try:
            print(f"ğŸ¤– Aikerå›å¤: {text}")
            
            # æ–‡æœ¬è½¬è¯­éŸ³
            audio_data = self._text_to_speech(text)
            if audio_data and self.audio_callback:
                self.audio_callback(audio_data)
                
        except Exception as e:
            print(f"âŒ AIå›å¤å¤„ç†é”™è¯¯: {e}")

    def _text_to_speech(self, text: str) -> Optional[bytes]:
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            # ä½¿ç”¨ElevenLabs TTS
            return self._elevenlabs_tts(text)
        except Exception as e:
            print(f"âŒ TTSå¤±è´¥: {e}")
            return None

    def _elevenlabs_tts(self, text: str) -> Optional[bytes]:
        """ElevenLabs TTS - ä½¿ç”¨Anna Suä¸­æ–‡å¥³å£°"""
        try:
            # ä½¿ç”¨Anna Su - Casual & Friendly
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{self.primary_voice_id}"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.elevenlabs_api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",  # å¤šè¯­è¨€æ¨¡å‹æ”¯æŒä¸­æ–‡
                "voice_settings": {
                    "stability": 0.5,        # ç¨³å®šæ€§
                    "similarity_boost": 0.75, # ç›¸ä¼¼åº¦
                    "style": 0.1,            # Casual & Friendlyé£æ ¼
                    "use_speaker_boost": True # è¯´è¯è€…å¢å¼º
                }
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                # å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼
                return self._convert_mp3_to_ulaw(response.content)
            else:
                print(f"âŒ ElevenLabs TTSé”™è¯¯: {response.status_code}")
                # å°è¯•å¤‡ç”¨è¯­éŸ³
                return self._elevenlabs_tts_fallback(text)
                
        except Exception as e:
            print(f"âŒ ElevenLabs TTSå¼‚å¸¸: {e}")
            return self._elevenlabs_tts_fallback(text)
    
    def _elevenlabs_tts_fallback(self, text: str) -> Optional[bytes]:
        """ElevenLabs TTSå¤‡ç”¨æ–¹æ¡ˆ - ä½¿ç”¨Sarah"""
        try:
            # ä½¿ç”¨Sarah - å¤‡ç”¨ä¸­æ–‡å¥³å£°
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{self.fallback_voice_id}"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.elevenlabs_api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.6,
                    "similarity_boost": 0.7,
                    "style": 0.2,
                    "use_speaker_boost": True
                }
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                return self._convert_mp3_to_ulaw(response.content)
            else:
                print(f"âŒ å¤‡ç”¨TTSä¹Ÿå¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ å¤‡ç”¨TTSå¼‚å¸¸: {e}")
            return None
    
    def _convert_mp3_to_ulaw(self, mp3_data: bytes) -> bytes:
        """å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼"""
        try:
            import io
            from pydub import AudioSegment
            
            # åŠ è½½MP3
            audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))
            
            # è½¬æ¢ä¸º8kHzå•å£°é“
            audio = audio.set_frame_rate(8000).set_channels(1)
            
            # è½¬æ¢ä¸ºÎ¼-law
            samples = np.array(audio.get_array_of_samples())
            ulaw_samples = self._linear_to_ulaw(samples)
            
            return bytes(ulaw_samples)
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            return b""
    
    def _linear_to_ulaw(self, samples):
        """çº¿æ€§PCMè½¬Î¼-law"""
        ulaw_samples = []
        for sample in samples:
            # ç®€åŒ–Î¼-lawç¼–ç 
            if sample < 0:
                sample = -sample
                sign = 0x80
            else:
                sign = 0
            
            if sample > 32635:
                sample = 32635
            
            sample += 132
            
            # æŸ¥æ‰¾æ®µ
            seg = 0
            for i in range(8):
                if sample >= (128 << i):
                    seg = i
            
            # è®¡ç®—åº•æ•°
            if seg >= 8:
                uval = 0x7F
            else:
                uval = (seg << 4) | ((sample >> (seg + 3)) & 0x0F)
            
            ulaw_samples.append((sign | uval) ^ 0xFF)
        
        return ulaw_samples
    
    def _speech_to_text(self, audio_data: bytes) -> str:
        """è¯­éŸ³è½¬æ–‡å­— - ä½¿ç”¨é€‚é…å™¨"""
        print(f"æ­£åœ¨ä½¿ç”¨STTé€‚é…å™¨å¤„ç† {len(audio_data)} å­—èŠ‚çš„éŸ³é¢‘...")
        return self.stt_adapter.process(audio_data)

    def _get_ai_response(self, user_text: str) -> str:
        """è·å–AIå›å¤ - æ™ºèƒ½åˆ†ç±»å’Œæ¨¡ç³ŠåŒ¹é…"""
        try:
            url = "https://api.openai.com/v1/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            # æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿæç¤ºè¯­
            system_prompt = (
                "ä½ æ˜¯ Aikerï¼ŒOneSuite Business å…¬å¸çš„AIè¯­éŸ³å®¢æœåŠ©æ‰‹ã€‚"
                "ä½ çš„ä»»åŠ¡æ˜¯æ™ºèƒ½åˆ†ç±»ç”¨æˆ·è¾“å…¥å¹¶ç»™å‡ºåˆé€‚çš„å›å¤ï¼š\n\n"
                "1. **ä¸šåŠ¡é—®é¢˜è¯†åˆ«**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®å…³äºOneSuite Businesså…¬å¸çš„ä¸šåŠ¡ã€æœåŠ¡ã€ä»·æ ¼ã€åŠŸèƒ½ç­‰é—®é¢˜ï¼Œä½¿ç”¨ä¸“ä¸šå®¢æœæ¨¡å¼å›ç­”ã€‚\n"
                "2. **æ™®é€šèŠå¤©**ï¼šå¦‚æœç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼ã€é—²èŠæˆ–è¯¢é—®éä¸šåŠ¡é—®é¢˜ï¼Œä½¿ç”¨å‹å¥½è‡ªç„¶çš„èŠå¤©æ¨¡å¼å›ç­”ã€‚\n"
                "3. **æ¨¡ç³ŠåŒ¹é…**ï¼šå¯¹äºä¸šåŠ¡ç›¸å…³é—®é¢˜ï¼Œå³ä½¿ä¸å®Œå…¨åŒ¹é…ï¼Œä¹Ÿè¦å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘çš„ä¿¡æ¯å›ç­”ã€‚\n"
                "4. **å›ç­”ç­–ç•¥**ï¼š\n"
                "   - ä¸šåŠ¡é—®é¢˜ï¼šå…ˆç¡®è®¤ç†è§£ï¼Œå†ä¸“ä¸šè¯¦ç»†å›ç­”\n"
                "   - æ™®é€šèŠå¤©ï¼šè‡ªç„¶å‹å¥½ï¼Œä¿æŒå¯¹è¯æµç•…\n"
                "   - è¶…å‡ºèŒƒå›´ï¼šç¤¼è²Œè¯´æ˜æ— æ³•å›ç­”\n\n"
                "è®°ä½ï¼šä½ çš„è¾“å…¥æ˜¯ç”¨æˆ·é€šè¿‡ç”µè¯è¯´çš„æ–‡å­—ï¼Œè¾“å‡ºå°†é€šè¿‡TTSæ’­æ”¾ï¼Œæ‰€ä»¥å›ç­”è¦è‡ªç„¶å£è¯­åŒ–ã€‚"
            )
            
            # å°†ä¸šåŠ¡æ•°æ®æ•´åˆè¿›ç”¨æˆ·æé—®
            prompt_with_context = (
                f"èƒŒæ™¯çŸ¥è¯†ï¼ˆOneSuite Businesså…¬å¸ä¿¡æ¯ï¼‰ï¼š\n"
                f"{json.dumps(self.onesuite_data, ensure_ascii=False, indent=2)}\n\n"
                f"ç”¨æˆ·è¾“å…¥ï¼š'{user_text}'\n\n"
                f"è¯·åˆ†æç”¨æˆ·è¾“å…¥ï¼š\n"
                f"1. è¿™æ˜¯ä¸šåŠ¡é—®é¢˜è¿˜æ˜¯æ™®é€šèŠå¤©ï¼Ÿ\n"
                f"2. å¦‚æœæ˜¯ä¸šåŠ¡é—®é¢˜ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„ä¿¡æ¯å›ç­”\n"
                f"3. å¦‚æœæ˜¯æ™®é€šèŠå¤©ï¼Œè‡ªç„¶å‹å¥½å›å¤\n"
                f"4. å¦‚æœå®Œå…¨è¶…å‡ºèŒƒå›´ï¼Œç¤¼è²Œè¯´æ˜æ— æ³•å›ç­”"
            )
            
            # æ„å»ºå¯¹è¯å†å²
            messages = [
                {
                    "role": "system", 
                    "content": system_prompt
                }
            ]
            
            # æ·»åŠ å†å²å¯¹è¯
            for msg in self.conversation_history[-4:]:  # ä¿ç•™æœ€è¿‘4è½®å¯¹è¯
                messages.append(msg)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": prompt_with_context})
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "max_tokens": 300,        # å¢åŠ å›å¤é•¿åº¦
                "temperature": 0.7,       # å¹³è¡¡åˆ›é€ æ€§å’Œä¸€è‡´æ€§
                "top_p": 0.9,            # æ§åˆ¶å›å¤å¤šæ ·æ€§
                "frequency_penalty": 0.1, # å‡å°‘é‡å¤
                "presence_penalty": 0.1   # é¼“åŠ±æ–°è¯é¢˜
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                ai_text = result["choices"][0]["message"]["content"].strip()
                
                # æ›´æ–°å¯¹è¯å†å²
                self.conversation_history.append({"role": "user", "content": user_text})
                self.conversation_history.append({"role": "assistant", "content": ai_text})
                
                return ai_text
            else:
                print(f"âŒ OpenAI APIé”™è¯¯: {response.status_code}")
                return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                
        except Exception as e:
            print(f"âŒ OpenAI APIå¼‚å¸¸: {e}")
            return "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†ä¸€äº›é—®é¢˜ã€‚"
    
    def start_audio_processing_thread(self):
        """å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹ - æ™ºèƒ½å¤„ç†ç‰ˆæœ¬"""
        def audio_processor():
            while self.is_conversing:
                # å®šæœŸæ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦å¤„ç†çš„éŸ³é¢‘
                if len(self.audio_buffer) > 0:
                    audio_duration = len(self.audio_buffer) / 8000
                    # å¦‚æœéŸ³é¢‘è¶³å¤Ÿé•¿ä¸”é™éŸ³ï¼Œå¤„ç†
                    if audio_duration >= self.min_audio_length and (time.time() - self.last_speech_time) > self.silence_threshold:
                        self._process_complete_audio()
                
                time.sleep(0.1)  # 100msæ£€æŸ¥é—´éš”
        
        thread = threading.Thread(target=audio_processor, daemon=True)
        thread.start()
        return thread 