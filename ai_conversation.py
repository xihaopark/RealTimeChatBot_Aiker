#!/usr/bin/env python3
"""
AIå¯¹è¯æ¨¡å— - é›†æˆSTTã€LLMã€TTSå®ç°æ™ºèƒ½è¯­éŸ³å¯¹è¯
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæé«˜è¯†åˆ«ç²¾åº¦ã€ä½¿ç”¨æ›´å¥½TTSã€ç­‰å¾…ç”¨æˆ·è¯´å®Œè¯
"""

import asyncio
import json
import time
import threading
import queue
import websockets
import aiohttp
import numpy as np
from typing import Optional, Callable
import os

class AIConversationManager:
    """AIå¯¹è¯ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        # åŠ è½½APIå¯†é’¥
        self.openai_api_key = self._load_api_key("openai.key")
        self.deepgram_api_key = self._load_api_key("deepgram.key")
        self.elevenlabs_api_key = self._load_api_key("elevenlabs.key")
        
        # å¯¹è¯çŠ¶æ€
        self.is_conversing = False
        self.conversation_history = []
        self.audio_queue = queue.Queue()
        
        # å›è°ƒå‡½æ•°
        self.audio_callback = None
        
        # è¯­éŸ³æ£€æµ‹å‚æ•° - ç®€åŒ–ç‰ˆæœ¬
        self.silence_threshold = 1.0  # é™éŸ³æ£€æµ‹é˜ˆå€¼ï¼ˆç§’ï¼‰
        self.min_audio_length = 0.5   # æœ€å°éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
        self.last_speech_time = 0     # ä¸Šæ¬¡è¯´è¯æ—¶é—´
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = b""
        self.is_processing = False
        
        print("ğŸ¤– Aiker AIå¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"âœ… OpenAI API: {'å·²é…ç½®' if self.openai_api_key else 'æœªé…ç½®'}")
        print(f"âœ… Deepgram API: {'å·²é…ç½®' if self.deepgram_api_key else 'æœªé…ç½®'}")
        print(f"âœ… ElevenLabs API: {'å·²é…ç½®' if self.elevenlabs_api_key else 'æœªé…ç½®'}")
    
    def _load_api_key(self, filename: str) -> str:
        """åŠ è½½APIå¯†é’¥"""
        try:
            with open(f"api_keys/{filename}", "r") as f:
                return f.read().strip()
        except:
            return ""
    
    def set_audio_callback(self, callback: Callable):
        """è®¾ç½®éŸ³é¢‘å›è°ƒå‡½æ•°"""
        self.audio_callback = callback
    
    def start_conversation(self):
        """å¼€å§‹å¯¹è¯"""
        self.is_conversing = True
        self.conversation_history = []
        print("ğŸ¤ å¼€å§‹Aiker AIå¯¹è¯...")
        
        # å‘é€æ¬¢è¿è¯­
        welcome_text = "æ‚¨å¥½ï¼æˆ‘æ˜¯Aikerï¼Œæ‚¨çš„AIåŠ©æ‰‹ã€‚å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
        self._process_ai_response(welcome_text)
    
    def stop_conversation(self):
        """åœæ­¢å¯¹è¯"""
        self.is_conversing = False
        print("ğŸ”‡ åœæ­¢Aiker AIå¯¹è¯")
    
    def process_audio_input(self, audio_data: bytes):
        """å¤„ç†éŸ³é¢‘è¾“å…¥ï¼ˆä»RTPæ¥æ”¶ï¼‰- ç®€åŒ–ç‰ˆæœ¬"""
        if not self.is_conversing:
            return
        
        # å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
        self.audio_buffer += audio_data
        self.last_speech_time = time.time()
        
        # æ£€æŸ¥éŸ³é¢‘é•¿åº¦
        audio_duration = len(self.audio_buffer) / 8000  # 8kHzé‡‡æ ·ç‡
        
        # å¦‚æœéŸ³é¢‘é•¿åº¦è¶³å¤Ÿï¼Œæ”¾å…¥é˜Ÿåˆ—ç­‰å¾…å¤„ç†
        if audio_duration >= 2.0:  # æ”¶é›†2ç§’éŸ³é¢‘
            if not self.audio_queue.full():
                self.audio_queue.put(self.audio_buffer)
                self.audio_buffer = b""
    
    def _process_audio_buffer(self):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº"""
        if self.is_processing:
            return
        
        self.is_processing = True
        
        try:
            # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
            audio_data = self.audio_queue.get_nowait()
            
            # è¯­éŸ³è½¬æ–‡æœ¬
            text = self._speech_to_text(audio_data)
            if text and len(text.strip()) > 0:
                print(f"ğŸ‘¤ ç”¨æˆ·è¯´: {text}")
                
                # è·å–AIå›å¤
                ai_response = self._get_ai_response(text)
                
                # å¤„ç†AIå›å¤
                self._process_ai_response(ai_response)
            
        except queue.Empty:
            pass
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
        finally:
            self.is_processing = False
    
    def _process_ai_response(self, text: str):
        """å¤„ç†AIå›å¤æ–‡æœ¬"""
        if not self.audio_callback:
            return
        
        print(f"ğŸ¤– Aikerå›å¤: {text}")
        
        # ç”Ÿæˆè¯­éŸ³
        audio_data = self._text_to_speech(text)
        if audio_data:
            # é€šè¿‡å›è°ƒå‘é€éŸ³é¢‘
            self.audio_callback(audio_data)
    
    def _text_to_speech(self, text: str) -> Optional[bytes]:
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            # ä½¿ç”¨ElevenLabs TTS - ä½¿ç”¨æ›´å¥½çš„ä¸­æ–‡å¥³å£°
            return self._elevenlabs_tts(text)
        except Exception as e:
            print(f"âŒ TTSå¤±è´¥: {e}")
            return None
    
    def _elevenlabs_tts(self, text: str) -> Optional[bytes]:
        """ElevenLabs TTS - ä½¿ç”¨Sarahä¸­æ–‡å¥³å£°"""
        try:
            import requests
            
            # ä½¿ç”¨Sarah - å¹´è½»å¥³å£°ï¼Œæ”¯æŒä¸­æ–‡
            url = "https://api.elevenlabs.io/v1/text-to-speech/EXAVITQu4vr4xnSDxMaL"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.elevenlabs_api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",  # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
                "voice_settings": {
                    "stability": 0.6,        # ç¨³å®šæ€§
                    "similarity_boost": 0.7,  # ç›¸ä¼¼åº¦
                    "style": 0.2,            # é£æ ¼
                    "use_speaker_boost": True # è¯´è¯è€…å¢å¼º
                }
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                # å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼
                return self._convert_mp3_to_ulaw(response.content)
            else:
                print(f"âŒ ElevenLabs TTSé”™è¯¯: {response.status_code}")
                # å°è¯•å¤‡ç”¨æ¨¡å‹
                return self._elevenlabs_tts_fallback(text)
                
        except Exception as e:
            print(f"âŒ ElevenLabs TTSå¼‚å¸¸: {e}")
            return self._elevenlabs_tts_fallback(text)
    
    def _elevenlabs_tts_fallback(self, text: str) -> Optional[bytes]:
        """ElevenLabs TTSå¤‡ç”¨æ–¹æ¡ˆ - ä½¿ç”¨Aria"""
        try:
            import requests
            
            # ä½¿ç”¨Aria - å¦ä¸€ä¸ªä¸­æ–‡å¥³å£°
            url = "https://api.elevenlabs.io/v1/text-to-speech/9BWtsMINqrJLrRacOk9x"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.elevenlabs_api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.6,
                    "similarity_boost": 0.7
                }
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                return self._convert_mp3_to_ulaw(response.content)
            else:
                print(f"âŒ å¤‡ç”¨TTSä¹Ÿå¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ å¤‡ç”¨TTSå¼‚å¸¸: {e}")
            return None
    
    def _convert_mp3_to_ulaw(self, mp3_data: bytes) -> bytes:
        """å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼"""
        try:
            import io
            from pydub import AudioSegment
            
            # åŠ è½½MP3
            audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))
            
            # è½¬æ¢ä¸º8kHzå•å£°é“
            audio = audio.set_frame_rate(8000).set_channels(1)
            
            # è½¬æ¢ä¸ºÎ¼-law
            samples = np.array(audio.get_array_of_samples())
            ulaw_samples = self._linear_to_ulaw(samples)
            
            return bytes(ulaw_samples)
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            return b""
    
    def _linear_to_ulaw(self, samples):
        """çº¿æ€§PCMè½¬Î¼-law"""
        ulaw_samples = []
        for sample in samples:
            # ç®€åŒ–Î¼-lawç¼–ç 
            if sample < 0:
                sample = -sample
                sign = 0x80
            else:
                sign = 0
            
            if sample > 32635:
                sample = 32635
            
            sample += 132
            
            # æŸ¥æ‰¾æ®µ
            seg = 0
            for i in range(8):
                if sample >= (128 << i):
                    seg = i
            
            # è®¡ç®—åº•æ•°
            if seg >= 8:
                uval = 0x7F
            else:
                uval = (seg << 4) | ((sample >> (seg + 3)) & 0x0F)
            
            ulaw_samples.append((sign | uval) ^ 0xFF)
        
        return ulaw_samples
    
    def _speech_to_text(self, audio_data: bytes) -> Optional[str]:
        """è¯­éŸ³è½¬æ–‡æœ¬ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            # ä½¿ç”¨Deepgram STT - ä¼˜åŒ–å‚æ•°
            return self._deepgram_stt(audio_data)
        except Exception as e:
            print(f"âŒ STTå¤±è´¥: {e}")
            return None
    
    def _deepgram_stt(self, audio_data: bytes) -> Optional[str]:
        """Deepgram STT - ä¼˜åŒ–å‚æ•°æé«˜ç²¾ç¡®åº¦"""
        try:
            import requests
            
            # ä¼˜åŒ–STTå‚æ•°
            url = "https://api.deepgram.com/v1/listen"
            
            params = {
                "model": "nova-2",           # ä½¿ç”¨æœ€æ–°çš„Nova-2æ¨¡å‹
                "language": "zh-CN",         # ä¸­æ–‡è¯†åˆ«
                "encoding": "mulaw",         # Î¼-lawç¼–ç 
                "sample_rate": "8000",       # 8kHzé‡‡æ ·ç‡
                "punctuate": "true",         # æ·»åŠ æ ‡ç‚¹ç¬¦å·
                "utterances": "true",        # å¯ç”¨è¯è¯­æ£€æµ‹
                "diarize": "false",          # ä¸è¿›è¡Œè¯´è¯è€…åˆ†ç¦»
                "smart_format": "true",      # æ™ºèƒ½æ ¼å¼åŒ–
                "filler_words": "false",     # è¿‡æ»¤å¡«å……è¯
                "profanity_filter": "false", # ä¸è¿‡æ»¤è„è¯
                "numerals": "true",          # æ•°å­—è¯†åˆ«
                "search": "",                # æ— æœç´¢è¯
                "replace": "",               # æ— æ›¿æ¢è¯
                "keywords": "",              # æ— å…³é”®è¯
                "interim_results": "false",  # ä¸éœ€è¦ä¸­é—´ç»“æœ
                "endpointing": "true",       # å¯ç”¨ç«¯ç‚¹æ£€æµ‹
                "vad_turnoff": "500"         # VADå…³é—­é˜ˆå€¼
            }
            
            headers = {
                "Authorization": f"Token {self.deepgram_api_key}",
                "Content-Type": "audio/mulaw"
            }
            
            response = requests.post(url, params=params, data=audio_data, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                return transcript.strip()
            else:
                print(f"âŒ Deepgram STTé”™è¯¯: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Deepgram STTå¼‚å¸¸: {e}")
            return None
    
    def _get_ai_response(self, user_text: str) -> str:
        """è·å–AIå›å¤ - ä¼˜åŒ–Aikerèº«ä»½"""
        try:
            import requests
            
            url = "https://api.openai.com/v1/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            # æ„å»ºå¯¹è¯å†å²
            messages = [
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯Aikerï¼Œä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·ç”¨è‡ªç„¶ã€æµç•…çš„ä¸­æ–‡å›å¤ç”¨æˆ·ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§å’Œå‹å¥½æ€§ã€‚ä½ çš„å›å¤åº”è¯¥ç®€æ´æ˜äº†ï¼Œä½†è¦æœ‰å¸®åŠ©æ€§ã€‚è®°ä½ä½ çš„åå­—æ˜¯Aikerã€‚"
                }
            ]
            
            # æ·»åŠ å†å²å¯¹è¯
            for msg in self.conversation_history[-4:]:  # ä¿ç•™æœ€è¿‘4è½®å¯¹è¯
                messages.append(msg)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_text})
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "max_tokens": 200,        # å¢åŠ å›å¤é•¿åº¦
                "temperature": 0.8,       # æé«˜åˆ›é€ æ€§
                "top_p": 0.9,            # æ§åˆ¶å›å¤å¤šæ ·æ€§
                "frequency_penalty": 0.1, # å‡å°‘é‡å¤
                "presence_penalty": 0.1   # é¼“åŠ±æ–°è¯é¢˜
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                ai_text = result["choices"][0]["message"]["content"].strip()
                
                # æ›´æ–°å¯¹è¯å†å²
                self.conversation_history.append({"role": "user", "content": user_text})
                self.conversation_history.append({"role": "assistant", "content": ai_text})
                
                return ai_text
            else:
                print(f"âŒ OpenAI APIé”™è¯¯: {response.status_code}")
                return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                
        except Exception as e:
            print(f"âŒ OpenAI APIå¼‚å¸¸: {e}")
            return "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†ä¸€äº›é—®é¢˜ã€‚"
    
    def start_audio_processing_thread(self):
        """å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹"""
        def audio_processor():
            while self.is_conversing:
                # å¤„ç†é˜Ÿåˆ—ä¸­çš„éŸ³é¢‘æ•°æ®
                if not self.audio_queue.empty():
                    self._process_audio_buffer()
                
                time.sleep(0.1)  # 100msæ£€æŸ¥é—´éš”
        
        thread = threading.Thread(target=audio_processor, daemon=True)
        thread.start()
        return thread 