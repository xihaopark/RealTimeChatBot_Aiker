#!/usr/bin/env python3
"""
AIå¯¹è¯æ¨¡å— - é›†æˆSTTã€LLMã€TTSå®ç°æ™ºèƒ½è¯­éŸ³å¯¹è¯
"""

import asyncio
import json
import time
import threading
import queue
import websockets
import aiohttp
import numpy as np
from typing import Optional, Callable
import os

class AIConversationManager:
    """AIå¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self):
        # åŠ è½½APIå¯†é’¥
        self.openai_api_key = self._load_api_key("openai.key")
        self.deepgram_api_key = self._load_api_key("deepgram.key")
        self.elevenlabs_api_key = self._load_api_key("elevenlabs.key")
        
        # å¯¹è¯çŠ¶æ€
        self.is_conversing = False
        self.conversation_history = []
        self.audio_queue = queue.Queue()
        
        # å›è°ƒå‡½æ•°
        self.audio_callback = None
        
        print("ğŸ¤– AIå¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"âœ… OpenAI API: {'å·²é…ç½®' if self.openai_api_key else 'æœªé…ç½®'}")
        print(f"âœ… Deepgram API: {'å·²é…ç½®' if self.deepgram_api_key else 'æœªé…ç½®'}")
        print(f"âœ… ElevenLabs API: {'å·²é…ç½®' if self.elevenlabs_api_key else 'æœªé…ç½®'}")
    
    def _load_api_key(self, filename: str) -> str:
        """åŠ è½½APIå¯†é’¥"""
        try:
            with open(f"api_keys/{filename}", "r") as f:
                return f.read().strip()
        except:
            return ""
    
    def set_audio_callback(self, callback: Callable):
        """è®¾ç½®éŸ³é¢‘å›è°ƒå‡½æ•°"""
        self.audio_callback = callback
    
    def start_conversation(self):
        """å¼€å§‹å¯¹è¯"""
        self.is_conversing = True
        self.conversation_history = []
        print("ğŸ¤ å¼€å§‹AIå¯¹è¯...")
        
        # å‘é€æ¬¢è¿è¯­
        welcome_text = "æ‚¨å¥½ï¼æˆ‘æ˜¯VTX AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
        self._process_ai_response(welcome_text)
    
    def stop_conversation(self):
        """åœæ­¢å¯¹è¯"""
        self.is_conversing = False
        print("ğŸ”‡ åœæ­¢AIå¯¹è¯")
    
    def process_audio_input(self, audio_data: bytes):
        """å¤„ç†éŸ³é¢‘è¾“å…¥ï¼ˆä»RTPæ¥æ”¶ï¼‰"""
        if not self.is_conversing:
            return
        
        # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        self.audio_queue.put(audio_data)
    
    def _process_ai_response(self, text: str):
        """å¤„ç†AIå›å¤æ–‡æœ¬"""
        if not self.audio_callback:
            return
        
        print(f"ğŸ¤– AIå›å¤: {text}")
        
        # ç”Ÿæˆè¯­éŸ³
        audio_data = self._text_to_speech(text)
        if audio_data:
            # é€šè¿‡å›è°ƒå‘é€éŸ³é¢‘
            self.audio_callback(audio_data)
    
    def _text_to_speech(self, text: str) -> Optional[bytes]:
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        try:
            # ä½¿ç”¨ElevenLabs TTS
            return self._elevenlabs_tts(text)
        except Exception as e:
            print(f"âŒ TTSå¤±è´¥: {e}")
            return None
    
    def _elevenlabs_tts(self, text: str) -> Optional[bytes]:
        """ElevenLabs TTS"""
        try:
            import requests
            
            url = "https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.elevenlabs_api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_monolingual_v1",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.5
                }
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                # å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼
                return self._convert_mp3_to_ulaw(response.content)
            else:
                print(f"âŒ ElevenLabs TTSé”™è¯¯: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ElevenLabs TTSå¼‚å¸¸: {e}")
            return None
    
    def _convert_mp3_to_ulaw(self, mp3_data: bytes) -> bytes:
        """å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼"""
        try:
            import io
            from pydub import AudioSegment
            
            # åŠ è½½MP3
            audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))
            
            # è½¬æ¢ä¸º8kHzå•å£°é“
            audio = audio.set_frame_rate(8000).set_channels(1)
            
            # è½¬æ¢ä¸ºÎ¼-law
            samples = np.array(audio.get_array_of_samples())
            ulaw_samples = self._linear_to_ulaw(samples)
            
            return bytes(ulaw_samples)
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            return b""
    
    def _linear_to_ulaw(self, samples):
        """çº¿æ€§PCMè½¬Î¼-law"""
        ulaw_samples = []
        for sample in samples:
            # ç®€åŒ–Î¼-lawç¼–ç 
            if sample < 0:
                sample = -sample
                sign = 0x80
            else:
                sign = 0
            
            if sample > 32635:
                sample = 32635
            
            sample += 132
            
            # æŸ¥æ‰¾æ®µ
            seg = 0
            for i in range(8):
                if sample >= (128 << i):
                    seg = i
            
            # è®¡ç®—åº•æ•°
            if seg >= 8:
                uval = 0x7F
            else:
                uval = (seg << 4) | ((sample >> (seg + 3)) & 0x0F)
            
            ulaw_samples.append((sign | uval) ^ 0xFF)
        
        return ulaw_samples
    
    def _speech_to_text(self, audio_data: bytes) -> Optional[str]:
        """è¯­éŸ³è½¬æ–‡æœ¬"""
        try:
            # ä½¿ç”¨Deepgram STT
            return self._deepgram_stt(audio_data)
        except Exception as e:
            print(f"âŒ STTå¤±è´¥: {e}")
            return None
    
    def _deepgram_stt(self, audio_data: bytes) -> Optional[str]:
        """Deepgram STT"""
        try:
            import requests
            
            url = "https://api.deepgram.com/v1/listen?model=nova-2&language=zh-CN&encoding=mulaw&sample_rate=8000"
            
            headers = {
                "Authorization": f"Token {self.deepgram_api_key}",
                "Content-Type": "audio/mulaw"
            }
            
            response = requests.post(url, data=audio_data, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                return transcript.strip()
            else:
                print(f"âŒ Deepgram STTé”™è¯¯: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Deepgram STTå¼‚å¸¸: {e}")
            return None
    
    def _get_ai_response(self, user_text: str) -> str:
        """è·å–AIå›å¤"""
        try:
            import requests
            
            url = "https://api.openai.com/v1/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            # æ„å»ºå¯¹è¯å†å²
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´ã€è‡ªç„¶çš„ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚ä¿æŒå¯¹è¯æµç•…ï¼Œå›ç­”è¦å®ç”¨ã€‚"}
            ]
            
            # æ·»åŠ å†å²å¯¹è¯
            for msg in self.conversation_history[-4:]:  # ä¿ç•™æœ€è¿‘4è½®å¯¹è¯
                messages.append(msg)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_text})
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": messages,
                "max_tokens": 150,
                "temperature": 0.7
            }
            
            response = requests.post(url, json=data, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                ai_text = result["choices"][0]["message"]["content"].strip()
                
                # æ›´æ–°å¯¹è¯å†å²
                self.conversation_history.append({"role": "user", "content": user_text})
                self.conversation_history.append({"role": "assistant", "content": ai_text})
                
                return ai_text
            else:
                print(f"âŒ OpenAI APIé”™è¯¯: {response.status_code}")
                return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                
        except Exception as e:
            print(f"âŒ OpenAI APIå¼‚å¸¸: {e}")
            return "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†ä¸€äº›é—®é¢˜ã€‚"
    
    def process_audio_buffer(self):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº"""
        if not self.is_conversing:
            return
        
        # æ”¶é›†éŸ³é¢‘æ•°æ®
        audio_buffer = b""
        start_time = time.time()
        
        while time.time() - start_time < 2.0:  # æ”¶é›†2ç§’éŸ³é¢‘
            try:
                audio_data = self.audio_queue.get_nowait()
                audio_buffer += audio_data
            except queue.Empty:
                time.sleep(0.1)
                continue
        
        if len(audio_buffer) > 0:
            # è¯­éŸ³è½¬æ–‡æœ¬
            text = self._speech_to_text(audio_buffer)
            if text and len(text.strip()) > 0:
                print(f"ğŸ‘¤ ç”¨æˆ·è¯´: {text}")
                
                # è·å–AIå›å¤
                ai_response = self._get_ai_response(text)
                
                # å¤„ç†AIå›å¤
                self._process_ai_response(ai_response)
    
    def start_audio_processing_thread(self):
        """å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹"""
        def audio_processor():
            while self.is_conversing:
                self.process_audio_buffer()
                time.sleep(0.1)
        
        thread = threading.Thread(target=audio_processor, daemon=True)
        thread.start()
        return thread 