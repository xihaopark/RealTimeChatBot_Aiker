#!/usr/bin/env python3
"""
VTX AI Phone System - ä¸»ç¨‹åºé›†æˆ (å¢å¼ºç‰ˆ)
é›†æˆæ–°çš„AIæä¾›å•†å’Œæµå¼å¼•æ“
"""

import sys
import os
import time
import signal
import threading
import asyncio
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import settings
from src.sip import SIPClient
from src.sdp import SDPParser
from src.rtp import RTPHandler
from src.audio import AudioGenerator

# æ–°å¢çš„AIç»„ä»¶å¯¼å…¥
from src.ai.providers.deepgram_provider import DeepgramSTTProvider, DeepgramConfig
from src.ai.providers.elevenlabs_provider import ElevenLabsTTSProvider, ElevenLabsConfig
from src.ai.enhanced.streaming_stt import StreamingSTTEngine, StreamingSTTConfig, STTProvider
from src.utils.api_manager import api_manager
from src.utils.performance_monitor import performance_monitor


class EnhancedVTXAIPhoneSystem:
    """å¢å¼ºç‰ˆ VTX AI ç”µè¯ç³»ç»Ÿ"""
    
    def __init__(self):
        # è·å–é…ç½®
        ext = settings.get_extension('101')
        if not ext:
            raise ValueError("åˆ†æœº 101 æœªé…ç½®")
        
        # åˆ›å»º SIP å®¢æˆ·ç«¯
        self.sip_client = SIPClient(
            server=settings.vtx.server,
            port=settings.vtx.port,
            domain=settings.vtx.domain,
            username=ext.username,
            password=ext.password
        )
        
        # AI ç»„ä»¶é…ç½®
        self.ai_enabled = True
        self.current_rtp_handler = None
        
        # åˆå§‹åŒ–AIç»„ä»¶
        if self.ai_enabled:
            self._init_enhanced_ai()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self.running = False
        
        print("ğŸ¯ å¢å¼ºç‰ˆ VTX AI ç”µè¯ç³»ç»Ÿ")
        print(f"æœåŠ¡å™¨: {settings.vtx.server}:{settings.vtx.port}")
        print(f"åŸŸå: {settings.vtx.domain}")
        print(f"DID: {settings.vtx.did_number}")
        print(f"åˆ†æœº: {ext.username}")
        print(f"AI: {'å¢å¼ºæ¨¡å¼' if self.ai_enabled else 'ç¦ç”¨'}")
        print("-" * 50)
    
    def _init_enhanced_ai(self):
        """åˆå§‹åŒ–å¢å¼ºAIç»„ä»¶"""
        print("ğŸ¤– åˆå§‹åŒ–å¢å¼ºAIç»„ä»¶...")
        
        try:
            # 1. æ£€æŸ¥APIå¯†é’¥
            missing_services = api_manager.get_missing_services()
            if missing_services:
                print(f"âš ï¸ ç¼ºå°‘APIå¯†é’¥: {', '.join(missing_services)}")
                print("   éƒ¨åˆ†AIåŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨")
            
            # 2. åˆå§‹åŒ–Deepgram STT
            if api_manager.has_key('deepgram'):
                deepgram_config = DeepgramConfig(
                    model="nova-2",
                    language="zh-CN",
                    interim_results=True,
                    endpointing=300
                )
                self.deepgram_provider = DeepgramSTTProvider(deepgram_config)
                print("âœ… Deepgram STT æä¾›å•†å·²åˆå§‹åŒ–")
            else:
                self.deepgram_provider = None
                print("âš ï¸ Deepgram STT ä¸å¯ç”¨ï¼ˆç¼ºå°‘APIå¯†é’¥ï¼‰")
            
            # 3. åˆå§‹åŒ–ElevenLabs TTS
            if api_manager.has_key('elevenlabs'):
                elevenlabs_config = ElevenLabsConfig(
                    voice_name="Rachel",
                    model_id="eleven_multilingual_v2",
                    stability=0.5,
                    similarity_boost=0.8
                )
                self.elevenlabs_provider = ElevenLabsTTSProvider(elevenlabs_config)
                print("âœ… ElevenLabs TTS æä¾›å•†å·²åˆå§‹åŒ–")
            else:
                self.elevenlabs_provider = None
                print("âš ï¸ ElevenLabs TTS ä¸å¯ç”¨ï¼ˆç¼ºå°‘APIå¯†é’¥ï¼‰")
            
            # 4. åˆå§‹åŒ–æµå¼STTå¼•æ“
            streaming_config = StreamingSTTConfig(
                primary_provider=STTProvider.DEEPGRAM if self.deepgram_provider else STTProvider.WHISPER_LOCAL,
                fallback_provider=STTProvider.WHISPER_LOCAL,
                auto_fallback=True,
                target_latency=0.8
            )
            self.streaming_stt_engine = StreamingSTTEngine(streaming_config)
            
            # è®¾ç½®å›è°ƒ
            self.streaming_stt_engine.set_transcript_callback(self._on_transcript)
            self.streaming_stt_engine.set_error_callback(self._on_ai_error)
            
            if self.elevenlabs_provider:
                self.elevenlabs_provider.set_audio_callback(self._on_tts_audio_ready)
                self.elevenlabs_provider.set_error_callback(self._on_ai_error)
            
            print("âœ… å¢å¼ºAIç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ AIç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ai_enabled = False
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†"""
        print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡é€€å‡º...")
        self.running = False
    
    async def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        # è®¾ç½®æ¥ç”µå¤„ç†
        self.sip_client.set_incoming_call_handler(self._handle_incoming_call)
        
        # å¯åŠ¨ SIP å®¢æˆ·ç«¯
        if not self.sip_client.start():
            print("âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥")
            return False
        
        # å¯åŠ¨å¢å¼ºAIç»„ä»¶
        if self.ai_enabled and self.streaming_stt_engine:
            await self.streaming_stt_engine.start()
        
        print("\nâœ… å¢å¼ºç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        print(f"ğŸ“ ç­‰å¾…æ¥ç”µ: {settings.vtx.did_number}")
        print("ğŸ¤– AIæ¨¡å¼: å¢å¼ºç‰ˆï¼ˆDeepgram + ElevenLabsï¼‰")
        print("æŒ‰ Ctrl+C é€€å‡º...\n")
        
        self.running = True
        
        # ä¸»å¾ªç¯
        try:
            while self.running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            pass
        
        # åœæ­¢ç³»ç»Ÿ
        await self.stop()
        
        return True
    
    async def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        print("\nğŸ›‘ åœæ­¢å¢å¼ºç³»ç»Ÿ...")
        
        # åœæ­¢AIç»„ä»¶
        if self.streaming_stt_engine:
            await self.streaming_stt_engine.stop()
        
        # åœæ­¢ SIP
        self.sip_client.stop()
        
        # æ‰“å°æ€§èƒ½æŠ¥å‘Š
        performance_monitor.print_performance_report()
        
        print("âœ… å¢å¼ºç³»ç»Ÿå·²åœæ­¢")
    
    def _handle_incoming_call(self, call, request):
        """å¤„ç†æ¥ç”µ"""
        print(f"\nğŸ“ æ¥ç”µ: {call.call_id}")
        
        # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
        call_start_time = time.time()
        
        # æå–æ¥ç”µä¿¡æ¯
        from_header = request.get_header('From')
        if from_header:
            import re
            match = re.search(r'sip:([^@]+)@', from_header)
            if match:
                caller = match.group(1)
                print(f"   æ¥ç”µå·ç : {caller}")
        
        # è§£æ SDP
        body = request.body
        if body:
            sdp = SDPParser.parse(body)
            rtp_info = SDPParser.extract_rtp_info(sdp)
            
            if rtp_info:
                remote_ip, remote_port, codecs = rtp_info
                print(f"   è¿œç¨‹ RTP: {remote_ip}:{remote_port}")
                print(f"   ç¼–è§£ç å™¨: {', '.join(codecs)}")
                
                # åˆ†é…æœ¬åœ° RTP ç«¯å£
                local_rtp_port = self.sip_client._get_next_rtp_port()
                
                # åˆ›å»º RTP å¤„ç†å™¨
                rtp_handler = RTPHandler(
                    self.sip_client.local_ip,
                    local_rtp_port
                )
                call.rtp_handler = rtp_handler
                self.current_rtp_handler = rtp_handler
                
                # è®¾ç½® RTP éŸ³é¢‘æ¥æ”¶å›è°ƒ
                if self.ai_enabled:
                    rtp_handler.set_audio_callback(self._on_rtp_audio_received)
                
                # æ„å»ºå“åº” SDP
                response_sdp = SDPParser.build(
                    self.sip_client.local_ip,
                    local_rtp_port,
                    codecs=codecs
                )
                
                # æ¥å¬ç”µè¯
                time.sleep(2)  # æ¨¡æ‹ŸæŒ¯é“ƒ
                self.sip_client._send_response(
                    request, 200, "OK",
                    to_tag=call.local_tag,
                    body=response_sdp
                )
                
                # å¯åŠ¨ RTP
                rtp_handler.start(remote_ip, remote_port)
                
                # è®°å½•å“åº”æ—¶é—´
                response_time = time.time() - call_start_time
                performance_monitor.record_response_time(response_time)
                
                if self.ai_enabled:
                    # AI æ¨¡å¼ï¼šæ’­æ”¾å¢å¼ºæ¬¢è¿è¯­
                    asyncio.create_task(self._play_enhanced_welcome())
                else:
                    # æµ‹è¯•æ¨¡å¼ï¼šå‘é€æµ‹è¯•éŸ³é¢‘
                    self._send_test_audio(rtp_handler)
            else:
                print("âš ï¸ æ— æ³•è§£æ RTP ä¿¡æ¯")
                self._send_busy_response(request, call)
        else:
            print("âš ï¸ æ²¡æœ‰ SDP")
            self._send_busy_response(request, call)
    
    def _send_busy_response(self, request, call):
        """å‘é€å¿™éŸ³å“åº”"""
        time.sleep(2)
        self.sip_client._send_response(
            request, 486, "Busy Here",
            to_tag=call.local_tag
        )
    
    async def _play_enhanced_welcome(self):
        """æ’­æ”¾å¢å¼ºæ¬¢è¿è¯­"""
        welcome_text = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯å¢å¼ºç‰ˆAIåŠ©æ‰‹ï¼Œæ­è½½äº†æœ€æ–°çš„è¯­éŸ³è¯†åˆ«å’ŒåˆæˆæŠ€æœ¯ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ"
        
        # ä½¿ç”¨ElevenLabsåˆæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.elevenlabs_provider:
            print(f"ğŸ”Š ä½¿ç”¨ElevenLabsåˆæˆæ¬¢è¿è¯­...")
            try:
                async with self.elevenlabs_provider as provider:
                    await provider.synthesize(welcome_text)
            except Exception as e:
                print(f"âŒ ElevenLabsåˆæˆå¤±è´¥: {e}")
                # å›é€€åˆ°ä¼ ç»Ÿæ¬¢è¿æ–¹å¼
                self._send_test_audio(self.current_rtp_handler)
        else:
            print("ğŸ”Š ä½¿ç”¨ä¼ ç»ŸéŸ³é¢‘æ¬¢è¿...")
            self._send_test_audio(self.current_rtp_handler)
    
    def _on_rtp_audio_received(self, audio_data: bytes):
        """RTP éŸ³é¢‘æ¥æ”¶å›è°ƒ"""
        # å°†éŸ³é¢‘ä¼ é€’ç»™å¢å¼ºSTTå¼•æ“
        if self.streaming_stt_engine and self.ai_enabled:
            self.streaming_stt_engine.add_audio(audio_data)
    
    def _on_transcript(self, text: str, is_final: bool):
        """è¯­éŸ³è¯†åˆ«ç»“æœå›è°ƒ"""
        if is_final:
            print(f"ğŸ‘¤ ç”¨æˆ·è¯´ï¼ˆæœ€ç»ˆï¼‰: {text}")
            # TODO: ä¼ é€’ç»™LLMå¤„ç†
            asyncio.create_task(self._process_user_input(text))
        else:
            print(f"ğŸ‘¤ ç”¨æˆ·è¯´ï¼ˆä¸­é—´ï¼‰: {text}")
    
    async def _process_user_input(self, text: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # ç®€å•çš„AIå›å¤é€»è¾‘ï¼ˆå¾…å®ç°å®Œæ•´LLMé›†æˆï¼‰
        ai_response = f"æˆ‘å¬åˆ°æ‚¨è¯´ï¼š{text}ã€‚è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å›å¤ã€‚"
        
        print(f"ğŸ¤– AI å›å¤: {ai_response}")
        
        # ä½¿ç”¨ElevenLabsåˆæˆå›å¤
        if self.elevenlabs_provider:
            try:
                async with self.elevenlabs_provider as provider:
                    await provider.synthesize(ai_response)
            except Exception as e:
                print(f"âŒ åˆæˆå›å¤å¤±è´¥: {e}")
    
    def _on_tts_audio_ready(self, audio_data: bytes, text: str):
        """TTSéŸ³é¢‘å°±ç»ªå›è°ƒ"""
        print(f"ğŸ”Š éŸ³é¢‘åˆæˆå®Œæˆ: {len(audio_data)} å­—èŠ‚")
        
        # é€šè¿‡ RTP å‘é€éŸ³é¢‘ï¼ˆéœ€è¦æ ¼å¼è½¬æ¢ï¼‰
        if self.current_rtp_handler:
            # TODO: å°†MP3è½¬æ¢ä¸ºÎ¼-lawæ ¼å¼
            # æš‚æ—¶ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆéœ€è¦æ”¹è¿›ï¼‰
            try:
                # ç®€å•åˆ†åŒ…å‘é€
                packet_size = 160
                for i in range(0, len(audio_data), packet_size):
                    packet = audio_data[i:i+packet_size]
                    if len(packet) < packet_size:
                        packet += b'\xFF' * (packet_size - len(packet))
                    
                    self.current_rtp_handler.send_audio(packet, payload_type=0)
                    time.sleep(0.02)  # 20msé—´éš”
                    
            except Exception as e:
                print(f"âŒ éŸ³é¢‘å‘é€å¤±è´¥: {e}")
    
    def _on_ai_error(self, error: str):
        """AIé”™è¯¯å›è°ƒ"""
        print(f"âŒ AIé”™è¯¯: {error}")
        performance_monitor.record_error()
    
    def _send_test_audio(self, rtp_handler):
        """å‘é€æµ‹è¯•éŸ³é¢‘ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰"""
        print("ğŸµ å‘é€æµ‹è¯•éŸ³é¢‘: 1871")
        
        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        test_audio = AudioGenerator.generate_test_pattern_1871()
        print(f"   éŸ³é¢‘é•¿åº¦: {len(test_audio)} å­—èŠ‚")
        
        # åˆ†åŒ…å‘é€
        packet_size = 160  # 20ms @ 8kHz
        for i in range(0, len(test_audio), packet_size):
            packet = test_audio[i:i+packet_size]
            if len(packet) < packet_size:
                packet += b'\xFF' * (packet_size - len(packet))
            
            rtp_handler.send_audio(packet, payload_type=0)
            time.sleep(0.02)  # 20ms
        
        print(f"âœ… æµ‹è¯•éŸ³é¢‘å‘é€å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("VTX AI Phone System v2.0 (Enhanced)")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥çŠ¶æ€
    print("ğŸ”‘ APIå¯†é’¥çŠ¶æ€æ£€æŸ¥...")
    available_services = api_manager.get_available_services()
    missing_services = api_manager.get_missing_services()
    
    print(f"âœ… å¯ç”¨æœåŠ¡: {', '.join(available_services) if available_services else 'æ— '}")
    if missing_services:
        print(f"âš ï¸ ç¼ºå¤±æœåŠ¡: {', '.join(missing_services)}")
    
    print("-" * 60)
    
    try:
        system = EnhancedVTXAIPhoneSystem()
        await system.start()
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    asyncio.run(main()) 