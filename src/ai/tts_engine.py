"""
è¯­éŸ³åˆæˆå¼•æ“ (Text-to-Speech)
ä½¿ç”¨ Edge-TTS æˆ– OpenAI TTS API
"""

import os
import asyncio
import queue
import threading
import tempfile
from typing import Optional, Callable, List
from dataclasses import dataclass
from enum import Enum
import numpy as np

try:
    import edge_tts
    HAS_EDGE_TTS = True
except ImportError:
    HAS_EDGE_TTS = False
    print("âš ï¸ Edge-TTS æœªå®‰è£…")

try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False


class TTSProvider(Enum):
    """TTS æä¾›å•†"""
    EDGE_TTS = "edge_tts"
    OPENAI = "openai"
    ELEVENLABS = "elevenlabs"


@dataclass
class TTSConfig:
    """TTS é…ç½®"""
    provider: TTSProvider = TTSProvider.EDGE_TTS
    voice: str = "zh-CN-XiaoxiaoNeural"  # Edge-TTS å£°éŸ³
    openai_voice: str = "alloy"  # OpenAI å£°éŸ³: alloy, echo, fable, onyx, nova, shimmer
    speed: float = 1.0  # è¯­é€Ÿ
    pitch: float = 0.0  # éŸ³è°ƒ
    volume: float = 1.0  # éŸ³é‡
    sample_rate: int = 16000  # è¾“å‡ºé‡‡æ ·ç‡
    api_key: Optional[str] = None  # OpenAI API å¯†é’¥


class TTSEngine:
    """è¯­éŸ³åˆæˆå¼•æ“"""
    
    # Edge-TTS ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
    CHINESE_VOICES = {
        "æ™“æ™“": "zh-CN-XiaoxiaoNeural",
        "äº‘å¸Œ": "zh-CN-YunxiNeural",
        "äº‘å¥": "zh-CN-YunjianNeural",
        "æ™“ä¼Š": "zh-CN-XiaoyiNeural",
        "äº‘æ‰¬": "zh-CN-YunyangNeural",
        "æ™“è¾°": "zh-CN-XiaochenNeural",
        "æ™“æ¶µ": "zh-CN-XiaohanNeural",
        "æ™“å¢¨": "zh-CN-XiaomoNeural",
        "æ™“ç§‹": "zh-CN-XiaoqiuNeural",
        "æ™“ç¿": "zh-CN-XiaoruiNeural",
        "æ™“åŒ": "zh-CN-XiaoshuangNeural",
        "æ™“å¦": "zh-CN-XiaoyanNeural",
        "äº‘æ«": "zh-CN-YunfengNeural",
        "äº‘çš“": "zh-CN-YunhaoNeural",
        "äº‘å¤": "zh-CN-YunxiaNeural",
        "äº‘é‡": "zh-CN-YunyeNeural",
        "äº‘æ³½": "zh-CN-YunzeNeural"
    }
    
    def __init__(self, config: Optional[TTSConfig] = None):
        """
        åˆå§‹åŒ– TTS å¼•æ“
        
        Args:
            config: TTS é…ç½®
        """
        self.config = config or TTSConfig()
        
        # ä»APIå¯†é’¥ç®¡ç†å™¨è·å–å¯†é’¥
        from src.utils.api_keys import get_api_key
        
        if self.config.provider == TTSProvider.EDGE_TTS:
            # Edge-TTS (å…è´¹)
            print(f"ğŸ”Š TTS å¼•æ“åˆå§‹åŒ–: {self.config.provider.value}")
            print(f"   è¯­éŸ³: {self.config.voice}")
            
        elif self.config.provider == TTSProvider.OPENAI:
            # OpenAI TTS
            api_key = self.config.api_key or get_api_key('openai')
            if not api_key or api_key.startswith('your_'):
                raise ValueError("æœªè®¾ç½® OpenAI API å¯†é’¥")
            
            import openai
            openai.api_key = api_key
            self.openai_client = openai
            
            print(f"ğŸ”Š TTS å¼•æ“åˆå§‹åŒ–: {self.config.provider.value}")
            print(f"   è¯­éŸ³: {self.config.openai_voice}")
            print(f"   APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
            
        elif self.config.provider == TTSProvider.ELEVENLABS:
            # ElevenLabs TTS
            api_key = self.config.api_key or get_api_key('elevenlabs')
            if not api_key or api_key.startswith('your_'):
                raise ValueError("æœªè®¾ç½® ElevenLabs API å¯†é’¥")
            
            try:
                from elevenlabs import generate, set_api_key
                set_api_key(api_key)
                self.elevenlabs_api_key = api_key
                print(f"ğŸ”Š TTS å¼•æ“åˆå§‹åŒ–: {self.config.provider.value}")
                print(f"   APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
            except ImportError:
                raise RuntimeError("ElevenLabs åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install elevenlabs")
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.task_queue = queue.Queue()
        self.result_queue = queue.Queue()
        
        # å¤„ç†çº¿ç¨‹
        self.running = False
        self.process_thread = None
        
        # äº‹ä»¶å¾ªç¯
        self.loop = None
        
        # å›è°ƒ
        self.on_audio_ready = None
    
    def start(self):
        """å¯åŠ¨ TTS å¼•æ“"""
        if self.running:
            return
        
        self.running = True
        self.process_thread = threading.Thread(target=self._process_loop, daemon=True)
        self.process_thread.start()
        
        print("ğŸ”Š TTS å¼•æ“å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ TTS å¼•æ“"""
        self.running = False
        if self.process_thread:
            self.process_thread.join(timeout=2)
        
        print("ğŸ”Š TTS å¼•æ“å·²åœæ­¢")
    
    def synthesize(self, text: str, priority: bool = False):
        """
        åˆæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            priority: æ˜¯å¦ä¼˜å…ˆå¤„ç†
        """
        if priority:
            # æ¸…ç©ºé˜Ÿåˆ—
            while not self.task_queue.empty():
                try:
                    self.task_queue.get_nowait()
                except queue.Empty:
                    break
        
        self.task_queue.put(text)
        print(f"ğŸ”Š æ·»åŠ åˆæˆä»»åŠ¡: {text[:20]}...")
    
    def _process_loop(self):
        """å¤„ç†å¾ªç¯"""
        # åˆ›å»ºäº‹ä»¶å¾ªç¯
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        
        while self.running:
            try:
                # è·å–ä»»åŠ¡
                text = self.task_queue.get(timeout=0.1)
                
                # æ‰§è¡Œåˆæˆ
                print(f"ğŸ”Š å¼€å§‹åˆæˆ: {text[:20]}...")
                audio_data = self.loop.run_until_complete(self._synthesize_async(text))
                
                if audio_data:
                    # è½¬æ¢ä¸º Î¼-law
                    ulaw_data = self._convert_to_ulaw(audio_data)
                    
                    # æ·»åŠ åˆ°ç»“æœé˜Ÿåˆ—
                    self.result_queue.put((ulaw_data, text))
                    
                    # è°ƒç”¨å›è°ƒ
                    if self.on_audio_ready:
                        self.on_audio_ready(ulaw_data, text)
                    
                    print(f"âœ… åˆæˆå®Œæˆ: {len(ulaw_data)} å­—èŠ‚")
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ TTS é”™è¯¯: {e}")
        
        # å…³é—­äº‹ä»¶å¾ªç¯
        self.loop.close()
    
    async def _synthesize_async(self, text: str) -> Optional[bytes]:
        """
        å¼‚æ­¥åˆæˆè¯­éŸ³
        
        Args:
            text: æ–‡æœ¬
            
        Returns:
            éŸ³é¢‘æ•°æ® (PCM16)
        """
        if self.config.provider == TTSProvider.EDGE_TTS:
            return await self._synthesize_edge_tts(text)
        elif self.config.provider == TTSProvider.OPENAI:
            return await self._synthesize_openai(text)
        elif self.config.provider == TTSProvider.ELEVENLABS:
            return await self._synthesize_elevenlabs(text)
        else:
            return None
    
    async def _synthesize_edge_tts(self, text: str) -> Optional[bytes]:
        """ä½¿ç”¨ Edge-TTS åˆæˆ"""
        try:
            # åˆ›å»ºé€šä¿¡å¯¹è±¡
            communicate = edge_tts.Communicate(
                text,
                self.config.voice,
                rate=f"{int((self.config.speed - 1) * 100):+d}%",
                pitch=f"{int(self.config.pitch * 50):+d}Hz",
                volume=f"{int((self.config.volume - 1) * 100):+d}%"
            )
            
            # åˆæˆåˆ°å†…å­˜
            audio_chunks = []
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_chunks.append(chunk["data"])
            
            # åˆå¹¶éŸ³é¢‘
            if audio_chunks:
                audio_data = b''.join(audio_chunks)
                
                # Edge-TTS è¿”å›çš„æ˜¯ MP3ï¼Œéœ€è¦è½¬æ¢
                return self._convert_mp3_to_pcm(audio_data)
            
            return None
            
        except Exception as e:
            print(f"âŒ Edge-TTS é”™è¯¯: {e}")
            return None
    
    async def _synthesize_openai(self, text: str) -> Optional[bytes]:
        """ä½¿ç”¨ OpenAI TTS åˆæˆ"""
        try:
            response = await asyncio.to_thread(
                self.openai_client.Audio.create,
                model="tts-1",
                voice=self.config.openai_voice,
                input=text,
                speed=self.config.speed
            )
            
            # OpenAI è¿”å› MP3
            return self._convert_mp3_to_pcm(response['data'])
            
        except Exception as e:
            print(f"âŒ OpenAI TTS é”™è¯¯: {e}")
            return None
    
    async def _synthesize_elevenlabs(self, text: str) -> Optional[bytes]:
        """ä½¿ç”¨ ElevenLabs TTS åˆæˆ"""
        try:
            from elevenlabs import generate
            audio_data = generate(text, voice_id=self.elevenlabs_api_key)
            return audio_data
        except Exception as e:
            print(f"âŒ ElevenLabs TTS é”™è¯¯: {e}")
            return None
    
    def _convert_mp3_to_pcm(self, mp3_data: bytes) -> Optional[bytes]:
        """
        å°† MP3 è½¬æ¢ä¸º PCM
        
        Args:
            mp3_data: MP3 æ•°æ®
            
        Returns:
            PCM æ•°æ® (16-bit, 16kHz)
        """
        try:
            import subprocess
            
            # ä½¿ç”¨ ffmpeg è½¬æ¢
            process = subprocess.Popen(
                [
                    'ffmpeg',
                    '-i', 'pipe:0',  # ä»æ ‡å‡†è¾“å…¥è¯»å–
                    '-f', 's16le',   # 16-bit PCM
                    '-ar', str(self.config.sample_rate),  # é‡‡æ ·ç‡
                    '-ac', '1',      # å•å£°é“
                    'pipe:1'         # è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
                ],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.DEVNULL
            )
            
            pcm_data, _ = process.communicate(mp3_data)
            return pcm_data
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢é”™è¯¯: {e}")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ pydubï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from pydub import AudioSegment
                import io
                
                audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))
                audio = audio.set_frame_rate(self.config.sample_rate)
                audio = audio.set_channels(1)
                audio = audio.set_sample_width(2)  # 16-bit
                
                return audio.raw_data
                
            except:
                return None
    
    def _convert_to_ulaw(self, pcm_data: bytes) -> bytes:
        """
        å°† PCM è½¬æ¢ä¸º Î¼-law
        
        Args:
            pcm_data: PCM æ•°æ® (16-bit)
            
        Returns:
            Î¼-law æ•°æ®
        """
        from ..audio import G711Codec
        
        # å¦‚æœæ˜¯ 16kHzï¼Œéœ€è¦é™é‡‡æ ·åˆ° 8kHz
        if self.config.sample_rate == 16000:
            # ç®€å•é™é‡‡æ ·ï¼ˆè·³è¿‡æ¯éš”ä¸€ä¸ªæ ·æœ¬ï¼‰
            pcm_array = np.frombuffer(pcm_data, dtype=np.int16)
            pcm_array = pcm_array[::2]  # é™é‡‡æ ·
            pcm_data = pcm_array.tobytes()
        
        return G711Codec.encode_buffer(pcm_data)
    
    def get_audio(self, timeout: float = 0.1) -> Optional[tuple[bytes, str]]:
        """
        è·å–åˆæˆçš„éŸ³é¢‘
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            (éŸ³é¢‘æ•°æ®, æ–‡æœ¬) æˆ– None
        """
        try:
            return self.result_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def set_callback(self, callback: Callable[[bytes, str], None]):
        """è®¾ç½®éŸ³é¢‘å°±ç»ªå›è°ƒ"""
        self.on_audio_ready = callback
    
    def set_voice(self, voice: str):
        """è®¾ç½®è¯­éŸ³"""
        if self.config.provider == TTSProvider.EDGE_TTS:
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„å®šä¹‰çš„ä¸­æ–‡è¯­éŸ³
            if voice in self.CHINESE_VOICES:
                self.config.voice = self.CHINESE_VOICES[voice]
            else:
                self.config.voice = voice
        elif self.config.provider == TTSProvider.OPENAI:
            self.config.openai_voice = voice
        elif self.config.provider == TTSProvider.ELEVENLABS:
            # ElevenLabs TTS ä¸éœ€è¦è®¾ç½®è¯­éŸ³
            pass
        
        print(f"ğŸ”Š åˆ‡æ¢è¯­éŸ³: {voice}")
    
    def list_voices(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„è¯­éŸ³"""
        if self.config.provider == TTSProvider.EDGE_TTS:
            return list(self.CHINESE_VOICES.keys())
        elif self.config.provider == TTSProvider.OPENAI:
            return ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
        elif self.config.provider == TTSProvider.ELEVENLABS:
            return []
        else:
            return []